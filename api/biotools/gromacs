{"name":"Gromacs","description":"Versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since it is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers.","homepage":"http://www.gromacs.org/","biotoolsID":"gromacs","biotoolsCURIE":"biotools:gromacs","version":[],"otherID":[],"relation":[],"function":[{"operation":[{"uri":"http://edamontology.org/operation_2476","term":"Molecular dynamics"}],"input":[{"data":{"uri":"http://edamontology.org/data_0883","term":"Structure"},"format":[{"uri":"http://edamontology.org/format_1476","term":"PDB"}]}],"output":[],"note":null,"cmd":null}],"toolType":["Command-line tool","Library","Suite"],"topic":[{"uri":"http://edamontology.org/topic_0176","term":"Molecular dynamics"}],"operatingSystem":["Linux"],"language":[],"license":"LGPL-2.1","collectionID":["BioExcel"],"maturity":"Mature","cost":"Free of charge","accessibility":null,"elixirPlatform":[],"elixirNode":[],"elixirCommunity":[],"link":[],"download":[{"url":"http://www.gromacs.org/Downloads","type":"Software package","note":null,"version":null}],"documentation":[{"url":"http://www.gromacs.org/Documentation","type":["General"],"note":null}],"publication":[{"doi":"10.1016/j.softx.2015.06.001","pmid":null,"pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"Gromacs: High performance molecular simulations through multi-level parallelism from laptops to supercomputers","abstract":"© 2015 The Authors.GROMACS is one of the most widely used open-source and free software codes in chemistry, used primarily for dynamical simulations of biomolecules. It provides a rich set of calculation types, preparation and analysis tools. Several advanced techniques for free-energy calculations are supported. In version 5, it reaches new performance heights, through several new and enhanced parallelization algorithms. These work on every level; SIMD registers inside cores, multithreading, heterogeneous CPU-GPU acceleration, state-of-the-art 3D domain decomposition, and ensemble-level parallelization through built-in replica exchange and the separate Copernicus framework. The latest best-in-class compressed trajectory storage format is supported.","date":"2015-01-01T00:00:00Z","citationCount":8067,"authors":[{"name":"Abraham M.J."},{"name":"Murtola T."},{"name":"Schulz R."},{"name":"Pall S."},{"name":"Smith J.C."},{"name":"Hess B."},{"name":"Lindah E."}],"journal":"SoftwareX"}},{"doi":"10.1002/jcc.20291","pmid":"16211538","pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"GROMACS: Fast, flexible, and free","abstract":"This article describes the software suite GROMACS (Groningen MAchine for Chemical Simulation) that was developed at the University of Groningen, The Netherlands, in the early 1990s. The software, written in ANSI C, originates from a parallel hardware project, and is well suited for parallelization on processor clusters. By careful optimization of neighbor searching and of inner loop performance, GROMACS is a very fast program for molecular dynamics simulation. It does not have a force field of its own, but is compatible with GROMOS, OPLS, AMBER, and ENCAD force fields. In addition, it can handle polarizable shell models and flexible constraints. The program is versatile, as force routines can be added by the user, tabulated functions can be specified, and analyses can be easily customized. Nonequilibrium dynamics and free energy determinations are incorporated. Interfaces with popular quantum-chemical packages (MOPAC, GAMES-UK, GAUSSIAN) are provided to perform mixed MM/QM simulations. The package includes about 100 utility and analysis programs. GROMACS is in the public domain and distributed (with source code and documentation) under the GNU General Public License. It is maintained by a group of developers from the Universities of Groningen, Uppsala, and Stockholm, and the Max Planck Institute for Polymer Research in Mainz. Its Web site is http://www.gromacs.org. © 2005 Wiley Periodicals, Inc.","date":"2005-12-01T00:00:00Z","citationCount":10349,"authors":[{"name":"Van Der Spoel D."},{"name":"Lindahl E."},{"name":"Hess B."},{"name":"Groenhof G."},{"name":"Mark A.E."},{"name":"Berendsen H.J.C."}],"journal":"Journal of Computational Chemistry"}},{"doi":"10.1063/5.0018516","pmid":"33032406","pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"Heterogeneous parallelization and acceleration of molecular dynamics simulations in GROMACS","abstract":"© 2020 Author(s).The introduction of accelerator devices such as graphics processing units (GPUs) has had profound impact on molecular dynamics simulations and has enabled order-of-magnitude performance advances using commodity hardware. To fully reap these benefits, it has been necessary to reformulate some of the most fundamental algorithms, including the Verlet list, pair searching, and cutoffs. Here, we present the heterogeneous parallelization and acceleration design of molecular dynamics implemented in the GROMACS codebase over the last decade. The setup involves a general cluster-based approach to pair lists and non-bonded pair interactions that utilizes both GPU and central processing unit (CPU) single instruction, multiple data acceleration efficiently, including the ability to load-balance tasks between CPUs and GPUs. The algorithm work efficiency is tuned for each type of hardware, and to use accelerators more efficiently, we introduce dual pair lists with rolling pruning updates. Combined with new direct GPU-GPU communication and GPU integration, this enables excellent performance from single GPU simulations through strong scaling across multiple GPUs and efficient multi-node parallelization.","date":"2020-10-07T00:00:00Z","citationCount":42,"authors":[{"name":"Pall S."},{"name":"Zhmurov A."},{"name":"Bauer P."},{"name":"Abraham M."},{"name":"Lundborg M."},{"name":"Gray A."},{"name":"Hess B."},{"name":"Lindahl E."}],"journal":"Journal of Chemical Physics"}},{"doi":"10.1007/978-3-319-15976-8_1","pmid":null,"pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"Tackling exascale software challenges in molecular dynamics simulations with GROMACS","abstract":"© Springer International Publishing Switzerland 2015.GROMACS is a widely used package for biomolecular simulation, and over the last two decades it has evolved from small-scale efficiency to advanced heterogeneous acceleration and multi-level parallelism targeting some of the largest supercomputers in the world. Here, we describe some of the ways we have been able to realize this through the use of parallelization on all levels, combined with a constant focus on absolute performance. Release 4.6 of GROMACS uses SIMD acceleration on a wide range of architectures, GPU offloading acceleration, and both OpenMP and MPI parallelism within and between nodes, respectively. The recent work on acceleration made it necessary to revisit the fundamental algorithms of molecular simulation, including the concept of neighborsearching, and we discuss the present and future challenges we see for exascale simulation - in particular a very fine-grained task parallelism. We also discuss the software management, code peer review and continuous integration testing required for a project of this complexity.","date":"2015-01-01T00:00:00Z","citationCount":474,"authors":[{"name":"Pall S."},{"name":"Abraham M.J."},{"name":"Kutzner C."},{"name":"Hess B."},{"name":"Lindahl E."}],"journal":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)"}},{"doi":"10.1093/bioinformatics/btt055","pmid":"23407358","pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"GROMACS 4.5: A high-throughput and highly parallel open source molecular simulation toolkit","abstract":"Motivation: Molecular simulation has historically been a low-throughput technique, but faster computers and increasing amounts of genomic and structural data are changing this by enabling large-scale automated simulation of, for instance, many conformers or mutants of biomolecules with or without a range of ligands. At the same time, advances in performance and scaling now make it possible to model complex biomolecular interaction and function in a manner directly testable by experiment. These applications share a need for fast and efficient software that can be deployed on massive scale in clusters, web servers, distributed computing or cloud resources.Results: Here, we present a range of new simulation algorithms and features developed during the past 4 years, leading up to the GROMACS 4.5 software package. The software now automatically handles wide classes of biomolecules, such as proteins, nucleic acids and lipids, and comes with all commonly used force fields for these molecules built-in. GROMACS supports several implicit solvent models, as well as new free-energy algorithms, and the software now uses multithreading for efficient parallelization even on low-end systems, including windows-based workstations. Together with hand-tuned assembly kernels and state-of-the-art parallelization, this provides extremely high performance and cost efficiency for high-throughput as well as massively parallel simulations. © 2013 The Author. Published by Oxford University Press. All rights reserved.","date":"2013-04-01T00:00:00Z","citationCount":4770,"authors":[{"name":"Pronk S."},{"name":"Pall S."},{"name":"Schulz R."},{"name":"Larsson P."},{"name":"Bjelkmar P."},{"name":"Apostolov R."},{"name":"Shirts M.R."},{"name":"Smith J.C."},{"name":"Kasson P.M."},{"name":"Van Der Spoel D."},{"name":"Hess B."},{"name":"Lindahl E."}],"journal":"Bioinformatics"}},{"doi":"10.1021/ct700301q","pmid":"26620784","pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"GRGMACS 4: Algorithms for highly efficient, load-balanced, and scalable molecular simulation","abstract":"Molecular simulation is an extremely useful, but computationally very expensive tool for studies of chemical and biomolecular systems. Here, we present a new implementation of our molecular simulation toolkit GROMACS which now both achieves extremely high performance on single processors from algorithmic optimizations and hand-coded routines and simultaneously scales very well on parallel machines. The code encompasses a minimal-communication domain decomposition algorithm, full dynamic load balancing, a state-of-the-art parallel constraint solver, and efficient virtual site algorithms that allow removal of hydrogen atom degrees of freedom to enable integration time steps up to 5 fs for atomistic simulations also in parallel. To improve the scaling properties of the common particle mesh Ewald electrostatics algorithms, we have in addition used a Multiple-Program, Multiple-Data approach, with separate node domains responsible for direct and reciprocal space interactions. Not only does this combination of algorithms enable extremely long simulations of large systems but also it provides that simulation performance on quite modest numbers of standard cluster nodes. © 2008 American Chemical Society.","date":"2008-03-01T00:00:00Z","citationCount":11812,"authors":[{"name":"Hess B."},{"name":"Kutzner C."},{"name":"Van Der Spoel D."},{"name":"Lindahl E."}],"journal":"Journal of Chemical Theory and Computation"}},{"doi":"10.1007/s008940100045","pmid":null,"pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"GROMACS 3.0: A package for molecular simulation and trajectory analysis","abstract":"GROMACS 3.0 is the latest release of a versatile and very well optimized package for molecular simulation. Much effort has been devoted to achieving extremely high performance on both workstations and parallel computers. The design includes an extraction of virial and periodic boundary conditions from the loops over pairwise interactions, and special software routines to enable rapid calculation of x-1/2. Inner loops are generated automatically in C or Fortran at compile time, with optimizations adapted to each architecture. Assembly loops using SSE and 3DNow! Multimedia instructions are provided for x86 processors, resulting in exceptional performance on inexpensive PC workstations. The interface is simple and easy to use (no scripting language), based on standard command line arguments with self-explanatory functionality and integrated documentation. All binary files are independent of hardware endian and can be read by versions of GROMACS compiled using different floating-point precision. A large collection of flexible tools for trajectory analysis is included, with output in the form of finished Xmgr/Grace graphs. A basic trajectory viewer is included, and several external visualization tools can read the GROMACS trajectory format.","date":"2001-12-01T00:00:00Z","citationCount":5702,"authors":[{"name":"Lindahl E."},{"name":"Hess B."},{"name":"van der Spoel D."}],"journal":"Journal of Molecular Modeling"}},{"doi":"10.1016/0010-4655(95)00042-E","pmid":null,"pmcid":null,"type":[],"version":null,"note":null,"metadata":{"title":"GROMACS: A message-passing parallel molecular dynamics implementation","abstract":"A parallel message-passing implementation of a molecular dynamics (MD) program that is useful for bio(macro)molecules in aqueous environment is described. The software has been developed for a custom-designed 32-processor ring GROMACS (GROningen MAchine for Chemical Simulation) with communication to and from left and right neighbours, but can run on any parallel system onto which a a ring of processors can be mapped and which supports PVM-like block send and receive calls. The GROMACS software consists of a preprocessor, a parallel MD and energy minimization program that can use an arbitrary number of processors (including one), an optional monitor, and several analysis tools. The programs are written in ANSI C and available by ftp (information: gromacs@chem.rug.nl). The functionality is based on the GROMOS (GROningen MOlecular Simulation) package (van Gunsteren and Berendsen, 1987; BIOMOS B.V., Nijenborgh 4, 9747 AG Groningen). Conversion programs between GROMOS and GROMACS formats are included. The MD program can handle rectangular periodic boundary conditions with temperature and pressure scaling. The interactions that can be handled without modification are variable non-bonded pair interactions with Coulomb and Lennard-Jones or Buckingham potentials, using a twin-range cut-off based on charge groups, and fixed bonded interactions of either harmonic or constraint type for bonds and bond angles and either periodic or cosine power series interactions for dihedral angles. Special forces can be added to groups of particles (for non-equilibrium dynamics or for position restraining) or between particles (for distance restraints). The parallelism is based on particle decomposition. Interprocessor communication is largely limited to position and force distribution over the ring once per time step. © 1995.","date":"1995-09-02T00:00:00Z","citationCount":6792,"authors":[{"name":"Berendsen H.J.C."},{"name":"van der Spoel D."},{"name":"van Drunen R."}],"journal":"Computer Physics Communications"}},{"doi":"10.1002/jcc.24030","pmid":null,"pmcid":null,"type":["Benchmarking study"],"version":null,"note":null,"metadata":{"title":"Best bang for your buck: GPU nodes for GROMACS biomolecular simulations","abstract":"© 2015 The Authors. Journal of Computational Chemistry Published by Wiley Periodicals, Inc.The molecular dynamics simulation package GROMACS runs efficiently on a wide variety of hardware from commodity workstations to high performance computing clusters. Hardware features are well-exploited with a combination of single instruction multiple data, multithreading, and message passing interface (MPI)-based single program multiple data/multiple program multiple data parallelism while graphics processing units (GPUs) can be used as accelerators to compute interactions off-loaded from the CPU. Here, we evaluate which hardware produces trajectories with GROMACS 4.6 or 5.0 in the most economical way. We have assembled and benchmarked compute nodes with various CPU/GPU combinations to identify optimal compositions in terms of raw trajectory production rate, performance-to-price ratio, energy efficiency, and several other criteria. Although hardware prices are naturally subject to trends and fluctuations, general tendencies are clearly visible. Adding any type of GPU significantly boosts a node's simulation performance. For inexpensive consumer-class GPUs this improvement equally reflects in the performance-to-price ratio. Although memory issues in consumer-class GPUs could pass unnoticed as these cards do not support error checking and correction memory, unreliable GPUs can be sorted out with memory checking tools. Apart from the obvious determinants for cost-efficiency like hardware expenses and raw performance, the energy consumption of a node is a major cost factor. Over the typical hardware lifetime until replacement of a few years, the costs for electrical power and cooling can become larger than the costs of the hardware itself. Taking that into account, nodes with a well-balanced ratio of CPU and consumer-class GPU resources produce the maximum amount of GROMACS trajectory over their lifetime.","date":"2015-10-01T00:00:00Z","citationCount":126,"authors":[{"name":"Kutzner C."},{"name":"Pall S."},{"name":"Fechner M."},{"name":"Esztermann A."},{"name":"De Groot B.L."},{"name":"Grubmuller H."}],"journal":"Journal of Computational Chemistry"}},{"doi":"10.1002/jcc.26011","pmid":null,"pmcid":null,"type":["Benchmarking study"],"version":null,"note":null,"metadata":{"title":"More bang for your buck: Improved use of GPU nodes for GROMACS 2018","abstract":"© 2019 Wiley Periodicals, Inc.We identify hardware that is optimal to produce molecular dynamics (MD) trajectories on Linux compute clusters with the GROMACS 2018 simulation package. Therefore, we benchmark the GROMACS performance on a diverse set of compute nodes and relate it to the costs of the nodes, which may include their lifetime costs for energy and cooling. In agreement with our earlier investigation using GROMACS 4.6 on hardware of 2014, the performance to price ratio of consumer GPU nodes is considerably higher than that of CPU nodes. However, with GROMACS 2018, the optimal CPU to GPU processing power balance has shifted even more toward the GPU. Hence, nodes optimized for GROMACS 2018 and later versions enable a significantly higher performance to price ratio than nodes optimized for older GROMACS versions. Moreover, the shift toward GPU processing allows to cheaply upgrade old nodes with recent GPUs, yielding essentially the same performance as comparable brand-new hardware. © 2019 Wiley Periodicals, Inc.","date":"2019-10-15T00:00:00Z","citationCount":124,"authors":[{"name":"Kutzner C."},{"name":"Pall S."},{"name":"Fechner M."},{"name":"Esztermann A."},{"name":"de Groot B.L."},{"name":"Grubmuller H."}],"journal":"Journal of Computational Chemistry"}}],"credit":[{"name":"GROMACS support","email":null,"url":"http://www.gromacs.org/support/mailing_lists","orcidid":null,"gridid":null,"rorid":null,"fundrefid":null,"typeEntity":"Person","typeRole":["Primary contact"],"note":null}],"community":null,"owner":"jdianes","additionDate":"2016-10-03T14:08:36Z","lastUpdate":"2022-07-12T14:34:44.386238Z","editPermission":{"type":"group","authors":["adam.hospital@irbbarcelona.org","gelpi@ub.edu","sergitobara"]},"validated":1,"homepage_status":0,"elixir_badge":0,"confidence_flag":null}