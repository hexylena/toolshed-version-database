{"model_class": "Tool", "id": "toolshed.g2.bx.psu.edu/repos/bgruening/llm_hub/llm_hub/1.100.0+galaxy0", "name": "LLM Hub", "version": "1.100.0+galaxy0", "description": "Call any LLM", "labels": [], "icon": null, "edam_operations": [], "edam_topics": [], "hidden": "", "is_workflow_compatible": true, "xrefs": [], "tool_shed_repository": {"name": "llm_hub", "owner": "bgruening", "changeset_revision": "130f0be3a275", "tool_shed": "toolshed.g2.bx.psu.edu"}, "inputs": [{"model_class": "Conditional", "name": "input_type", "type": "conditional", "cases": [{"model_class": "ConditionalWhen", "value": "multimodal", "inputs": [{"model_class": "SelectToolParameter", "name": "model", "argument": null, "type": "select", "label": "Model", "help": "Select the model you want to use.", "help_format": "html", "refresh_on_change": false, "optional": false, "hidden": false, "is_dynamic": true, "value": "gemma-3-12b-llmlb", "options": [["Handles text + images, great for describing photos, diagrams, or screenshots (Gemma-3-12B-IT)", "gemma-3-12b-llmlb", false], ["Budget-friendly image understanding, extract info from charts, UIs, or screenshots (Qwen2.5-VL-7B-Instruct)", "qwen2.5-vl-7b-llmlb", false], ["High-performance multimodal model for complex reasoning and image understanding (Gemma-3-27B-IT)", "gemma-3-27b-llmlb", false], ["Advanced vision-language model for detailed image analysis and conversation (Qwen3-VL-32B)", "qwen3-vl-32b-llmlb", false]], "display": null, "multiple": false, "textable": false}, {"model_class": "DataToolParameter", "name": "context", "argument": null, "type": "data", "label": "Context", "help": "", "help_format": "html", "refresh_on_change": true, "optional": false, "hidden": false, "is_dynamic": false, "value": null, "extensions": ["html", "json", "txt", "jpg", "png", "gif"], "edam": {"edam_formats": ["format_2331", "format_3464", "format_2330", "format_3579", "format_3603", "format_3467"], "edam_data": ["data_0006", "data_0006", "data_0006", "data_2968", "data_2968", "data_2968"]}, "multiple": true, "min": null, "max": 500, "options": {"dce": [], "ldda": [], "hda": [], "hdca": []}, "tag": null}]}, {"model_class": "ConditionalWhen", "value": "text", "inputs": [{"model_class": "SelectToolParameter", "name": "model", "argument": null, "type": "select", "label": "Model", "help": "Select the model you want to use.", "help_format": "html", "refresh_on_change": false, "optional": false, "hidden": false, "is_dynamic": true, "value": "gpt-oss-120b-llmlb", "options": [["Most capable for complex tasks, deep reasoning, and detailed outputs (GPT-OSS-120B)", "gpt-oss-120b-llmlb", false], ["Strong all-rounder for technical tasks, coding, and long structured outputs (Qwen3-30B-A3B)", "qwen-30b-a3b-llmlb", false], ["Fast and efficient for general reasoning and straightforward problem-solving (DeepSeek-R1-0528-Qwen3-8B)", "deepseek-r1-0528-qwen3-8b-llmlb", false], ["Balanced accuracy and speed, good for drafting documents and structured outputs (Mistral-Small-3.2-24B-Instruct-2506-FP8)", "mistral-3.2-24b-llmlb", false], ["Lightweight and responsive, suitable for simpler tasks and fast prompt execution (Meta-Llama-3.1-8B-Instruct-FP8-dynamic)", "llama-3.1-8b-fp8-llmlb", false], ["Smooth for straightforward Q&A or text generation, efficient on small servers (GPT-OSS-20B)", "gpt-oss-20b-llmlb", false], ["Quick and lightweight text generation, best when speed and cost matter most (Magistral-Small-2507)", "magistral-small-llmlb", false], ["Specialized code generation model with strong reasoning capabilities (Qwen3-Coder-30B-A3B)", "qwen3-coder-30b-a3b-instruct-llmlb", false], ["Balanced and efficient model for general-purpose tasks (GLM-4-Air)", "glm45-air-llmlb", false], ["Compact and fast model for low-latency text generation (Voxtral-Mini)", "voxtral-mini-llmlb", false], ["Latest generation model with enhanced reasoning and knowledge (GLM-4.7)", "glm-4.7-llmlb", false]], "display": null, "multiple": false, "textable": false}, {"model_class": "DataToolParameter", "name": "context", "argument": null, "type": "data", "label": "Context", "help": "", "help_format": "html", "refresh_on_change": true, "optional": false, "hidden": false, "is_dynamic": false, "value": null, "extensions": ["docx", "html", "json", "pdf", "txt"], "edam": {"edam_formats": ["format_2333", "format_2331", "format_3464", "format_3508", "format_2330"], "edam_data": ["data_0006", "data_0006", "data_0006", "data_2968", "data_0006"]}, "multiple": true, "min": null, "max": 500, "options": {"dce": [], "ldda": [], "hda": [], "hdca": []}, "tag": null}]}], "test_param": {"model_class": "SelectToolParameter", "name": "input_type_selector", "argument": null, "type": "select", "label": "Choose the model", "help": "Multimodal models are capable to have image and text as input.", "help_format": "html", "refresh_on_change": true, "optional": false, "hidden": false, "is_dynamic": false, "value": "multimodal", "options": [["Multimodal models", "multimodal", true], ["Text models", "text", false]], "display": null, "multiple": false, "textable": false}}, {"model_class": "TextToolParameter", "name": "prompt", "argument": null, "type": "text", "label": "Prompt", "help": "Prompts or tasks you want the LLM to perform.", "help_format": "html", "refresh_on_change": false, "optional": false, "hidden": false, "is_dynamic": false, "value": null, "area": true, "datalist": []}], "outputs": [{"model_class": "ToolOutput", "name": "output", "format": "markdown", "label": "${tool.name} on ${on_string}", "hidden": false, "output_type": "data", "format_source": null, "default_identifier_source": "None", "metadata_source": null, "parent": null, "count": 1, "from_work_dir": "./output.md", "edam_format": "format_2330", "edam_data": "data_0006", "discover_datasets": []}], "panel_section_id": "machine_learning", "panel_section_name": "Machine Learning", "form_style": "regular"}